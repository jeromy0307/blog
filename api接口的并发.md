# api接口的并发
30万数据，尚且还可以处理过来，可是现在数据达到了41万，我启动了一个tornado进程方法都用的异步。
客户端连接超时时间120秒，都超时异常。之前没有这种情况，一开始数据量小的时候，tornado的响应
时间均在2秒左右，后来慢慢的上升之6秒左右。

现在还只有20个线程同时访问。

这叫什么并发，人家的并发都是单进程可以跑2000多个线程。我这才20个线程就顶不住了。

那我提高客户端的线程数来做，现在我将客户端的线程数提高到2000，tornado进程数不变，我来测试。

经过我测试，发现tornado处理的速度特别快，但是还是存在客户端不能创建请求的过程。那么问题出在哪里了呢？

弄上负载均衡nginx反向代理。

由于上一个实验造成tornado单进程，客户端存在大量超时连接。所以，这次准备利用反向代理来慢慢增加tornado的
进程数，然后来试试。

首先，我装了一台nginx的服务器ubuntu虚拟机。

然后再装两台部署tornado应用的ubuntu虚拟机。

为了慢慢的查看tornado的性能，所以我准备慢慢增加tornado进程数。

PS. 由于之前的一个app，说数百万并发，现在我把之前的app经历拿到这里，发现20多个都顶不住，那么，如何去谈
百万并发的app呢？这里我感觉很不靠谱了。

我测试了下单条mysql查询，发现查询速度很快只需要0.718秒，这说明不是我的myslq性能慢，从这里，至少可以
推断出，可能是写数据库操作导致等待，那么我的mysql表的引擎室inodb，网上有人说
inodb.

当然，我要去搜索这个问题的原因是，那是因为我做了一个测试，就是当我把程序全部关掉之后，执行单个查询语句的速度是0.718秒，那么问题来了，如果我把程序再开起来，这个速度会稳定吗？假设稳定，就可以断定，是因为inodb的高并发写入表的操作引起了速度的tornado并发性能的下降。

那么，再做一次实验，首先开启tornado服务端单进程，然后开启客户端2000个线程。现在再到mysql workbench上查询一次，看看速度是多少？

引申一些条件，由于一开始我的数据库已经有了30多万电影数据，这次虽然又增加了10万多的数据，但是写入也只是写入了10多万数据，这样存在高并发吗？平均每秒都不超过20个插入，怎么可能会存在高并发写入的问题呢？

所以，最后基本能够确定的问题有亮点：
* tornado mac单进程处理能力不行;
* 很小的因素在mysql这边；

算了直接贴上知乎上大神的评论。
https://www.zhihu.com/question/23445395

首先我筛选前几个答案，因为这些答案比较靠前，所以就用这几个作为参考。

## 关于insert高并发是用inodb还是myiasm
### 答案1
TokuDB--它的fractal tree（其实就是buffered tree）能把随机IO变为顺序IO，写入性能极强，我们测试在HDD是InnoDB的3倍以上~Myisam官方已经放弃维护了，虽然插入性能也行，但不是crash safe且crash后恢复时间长，而且只有索引能缓存在内存中，所以都不一定比有热数据缓存的的InnoDB快；不要用了~

作者：刀尖红叶
链接：https://www.zhihu.com/question/23445395/answer/62345043
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

### 答案2
选择innodb还是MyISAM

如果不是对事物要求非常的强，高并发写推荐myisam。理由如下：

  1. myisam的索引和数据是分开的，并且索引是有压缩的，内存使用率就相应提高了不少，能加载更多索引，而innodb是所以和数据是紧密捆绑的，没有使用压缩从而造成innodb比myisam的体积庞大不少；
  2. innodb 存储引擎在插入数据时会花更多的开销在维护完整性，维持事物上，所以效率比myisam低；
  3. 主要是插入数据，并且只有一张表，后期对该表的操作主要是查询，就是查询速度而言，myisam比innodb更优越，并且还有myisam索引，可以很好的优化查询速度。

如何提高insert效率

假设每秒5W~7W的量，并且数据是实时产生的，如何优化？

1. 批量插入values，而不是每一次都插入一条数据；
2. 删除mysql都索引，有索引存在插入速度会受很大的影响；
3. 增加主键；

### 答案3
作者：吴强 Daniel
链接：https://www.zhihu.com/question/23445395/answer/52080020
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

单线程MyISAM插入更快. innodb_flush_log_at_trx_commit=1, 禁止auto commit, 不要用单个线程或者进程插入, 同时模拟100个客户端插入, 你会发现InnoDB插入比MyISAM快. 当你更新的数据主键非常离散的时候, InnoDB可以用多个row lock而MyISAM总是lock整个table一条一条插入, MyISAM会比InnoDB慢. 事实上, MyISAM严格意义上根本不算是个数据库引擎, 最多算个结构化文件存储引擎. 在我的MBP上32个线程总共插入32万条记录, MyISAM大概是17.5秒, InnoDB大概16秒不到, 32个线程随机更新更新是MyISAM 23秒对InnoDB 19秒. 我的MBP是多通道的SSD, 如果在硬盘上测试差距会更大. 所以, 好多同学在单线程下auto-commit的测试来证明MyISAM比InnoDB快是不靠谱的. 但是无论如何, 大量插入还是NoSQL方便, 你7万的tps已经很高了, 已经非常不适合MySQL了, 如果只是峰值这样高, 建议你用文件或者队列buffer一下慢慢插, 如果是持续性的这样的TPS, 建议用append类型的NoSQL, 比如cassandra 和 redis. Netflix曾经在AWS上做过实验,288个m1el节点可以达到每秒一百万次写入, 基于SSD的商业数据库Aerospike更是只要50个节点 (参考 Daniel's Blog: Cassandra and Aerospike, the one million TPS war).

不过由于上面的测试还没开始，要等mac上复制文件完毕才能。

# 总结
通过这次并发方面的探索，我总结出下面一些要点：
* 并发要看cpu的核心数，linux系统的优化成都；
* 并发要看tornado应用的设置；
* 并发要看mysql方面的设置；

就本次优化过程而言，最终决定采用慢慢增加tornado进程数的方法也就是负载均衡的方法来解决本次的问题，如果再出现客户端还是大量超时的情况，我觉得就只能再增加tornado的进程数，后端的程序代码，我都是手写的，读写分离数据库，很简单。就算到时候，是因为查询速度太慢，我这里也没有办法解决，因为查询我都是用的精确字符串，没有用到模糊匹配的方式来查询。因为当你查询一件商品是否存在数据库的时候，一定是用字符串去匹配。

所以，最终的并发优化的方式，就是，增加应用的配置（机器的配置增加就是单机增加物理机器的配置，负载均衡，就是横向扩展增加机器集群来抗压力）。

这里假设瓶颈是卡在了mysql上，那么，似乎是无法优化的，mysql的速度慢了，那么，就算你tornado无限多，mysql一直柱塞，也根本就没什么办法。

后期我会增加我做了负载均衡上面测试之后的测试结果。

不知为何mac上的文件复制有问题，我将移动硬盘上的30多g的文件夹复制到mac上，mac就是不能用fiddler打开。

本来昨天就准备做负载均衡测试和tornado并发调优的实验的。

因为只有搞定了这个，我的项目的后续工作才能展开。

可是当我把客户端和服务端都启动起来之后发现，mysql的查询也非常的快，那么可以断定了，就是tornado搞不过来。看来我得多启动几个了。

由于我用的是mac，所以不知道能否发挥tornado的异步优势，所以，下次得到linux下测试才能得到结果。可能不是tornado的锅。

python的异步有点不可靠，可能是人的不可靠。

这次我说了，以后，如果要设计api接口的话，我尽量不用异步；
然后，如果要设计涉及支付的api接口，我尽量用java来写。

这python或者说我的能力不足以驾驭这门语言。so？就这样放弃了？

我的意思是说，做爬虫，我用python，但是做api接口我要用java。所以，似乎我也要开始准备我的java开发之路了，就是
用java来重构pyhton写的api接口。

问题是，我的mysql连接池有问题。由于是轮训，并且，算了不想说了，这里的问题很难处理。由于默认的连接池已经使用
，所以导致没有mysql连接可以使用，所以，导致，tornado超时，tornado超时就是超时在获取可用的mysql连接这里。

我都想换语言了。虽然这些东西都是自己设计都，运行环境也是极低的。但是这不能说明问题。

一开始我觉得是mysql连接池不够用，从而导致一直轮训获取连接，结果，这次我客户端启动5个线程，tornado都处理不过来。当然是单进程的 tornado，我的目标是让tornado处理2000个连接。可是现在，连5个并发访问都可能会出现问题。
当然这是在mac下做的测试。总体来说，心情不是很好。

场景是，5个线程同时抓数据，然后将数据发送到api接口，当然这个请求的数据很大，每次大概要插入24个，so这些数据在插入数据库之前必须验证数据库中不存在，mysql里有一个insert ignore into，这个可以一试。要是还是慢，那么，再想
办法。

得，经过这mysql语句的优化，导致我的程序由以前的7秒，现在只要160毫秒，1000毫秒等于1秒，7000 / 160 ,性能大概提高了45倍。真是可怕。

然后今天弄了集群：

所有机器配置：
* 都是些虚拟机 1G内存，1核cpu

部署:
| 服务器ip | 用途 | 其它 |
| -------- | ---- | ---- |
| 192.168.80.2 | 消息队列 | |
| 192.168.80.4 | mysql主数据库| |
| 192.168.80.6 | mysql从数据库| |
| 192.168.80.10 | 数据中心服务 | 上面开了两个tornado进程 |
| 192.168.80.5 | redis缓存 | |
| 192.168.80.9 | nginx网关 | |
| 我的测试机器 | 用语做并发测试 | |

上面就是基本的机器分布情况，经过测试，400个进程向数据中心发送数据，当然数据中心处理数据都是要对数据库进行操作的，总的来说比较稳定。
一开始我用了2000个线程，首先服务器500内部错误，然后网关超时，再消息队列也出问题，后来我又降线程，1500，同样的错误，最多的是网关超时，
然后1000出现了服务器内部错误，我的tonrnado都是异步的，接着504 网关超时.

最后我将线程数改为1000，nginx网关就一直超时，烦得很。nginx不是情轻轻松松百万并发都没问题吗？我现在才1000个线程连接nginx,nginx就扛不住了。
当我 查询了 nginx 504错误的时候，再次将客户端我的mac的线程数改为了2000（我的mac也进行了特殊设置，不然开不了2000个socket），服务器不再
504错误了，进而来的是服务器内部错误。

这种一步步向胜利靠近的心情无以言表。现在我的tornado终于能处理1500个线程的同时访问了。

然而，过来一回之后，又出现了服务器内部错误，500。

那么这里出现了一个问题是，当负载高的时候（就是客户端连接多的时候，tornado服务器会出现500错误），这是什么原因造成的？
可能存在的问题是：
* 代码本身就有问题；

为了验证代码没问题，那么我将线程数改为1000再试试。

真的烦，想当初就不该用api接口来存储爬虫数据，不过这也锻炼来我以后做api接口并发的能力。其实，吗的，2000个线程这么少，但是tornado出现了
服务器内部错误.然后，500个线程也还是出现超时。


解决nginx 504错误:
```

	之前线上的服务，最近访问量大了之后，nginx的error日志中大量出现upstream timed out (110: Connection timed out) while reading response header from upstream这种错误。

	虽然目前为止，问题的根本还是没有太清楚，但是先记一下自己的排查方法，明天可以继续排查：

	1.这个错误是说upstream时候读取对应的接口服务time out。我第一个想到的就是排查我的接口服务。

	接口服务是用tornado实现的，其中还会去访问其他的接口，访问接口使用了asynchttpclient，异步访问。

	查资料显示同步方法requests底层也有连接池，同事使用requests并没有出现我这种现象。是否是因为程序本身访问其他接口导致的时间太长的time out呢？

	1）我设置了asyncHttpclient的connect_timeout=2s，request_timeout=1s。按照道理来说，最迟3s就一定会返回结果或者返回错误。

	2）请求超时，我会返回一个空的结果集，因为即使超过了3s，我也会捕捉到异常，返回空结果

	以上我觉得不是这块的问题。

	那会不会是其他地方，比如调用mongodb或者aerospike时连接超时呢？

	于是，我在prepare方法中加上了开始时间，在finish中计算整个过程所用时间。如果大于2s就打出这条uri的log信息以及耗时。为了检验是否可行，我在测试环境中在程序里写死time.sleep(3)，这样验证了这个log记录方法的可行性。

	但是，发现并没有log日志。那又是为什么呢？？



	2.搜索了很多网上方法，都说设置nginx的proxy_read_timeout,proxy_send_timeout和proxy_buffer几个相关设置的值，设置为60啊150都有。但是这种方法只是延长了响应时间，并不是特别推荐。



	3.今天又重新分析了一下问题，发现报错信息上基本都是一台服务器的问题。因此考虑可能是那台服务器的配置有问题。因为是connection timeout，考虑是否是因为连接数设置问题。

	1）ps -aux | grep supervisor，查到supervisor的pid

	2）cat /proc/{pid}/limits，发现max open file为1024，这显然不是我们想要的

	3）grep -i file /etc/systemd/system.conf 修改DefaultLimitNOFILE=819200和grep -i file /etc/systemd/user.conf 的DefaultLimitNOFILE=819200

	4）重启supervisor。/etc/init.d/supervisor stop /etc/init.d/supervisor start

	5）查看当前启动的supervisor的limits中max open file数。

这是来自网络的，最后加一句要重启操作系统。
```

接着优化：

mac 系统出现了 BlockingIOError: [Errno 36] Operation now in progress   这个错误。
得到知识：
	LINUX socket 在connect的时候发生 Operation now in progress 错误
	原创 2014年03月06日 11:51:14 标签：socket /connect /Operation now in pro 9949
	解决方法：
	unsigned long ul = 1;
	ioctl( sockfd, FIONBIO, &ul );  //设置为非阻塞模式
	放到connect()后面.

那么requests如何用非柱塞的socket?
没有答案。

我的目标一直是2000个连接同时并发，要是做不到，我就觉得很失败。

当我将客户端线程数改为2000的时候，nginx 错误日志出现了 too many open files.那么又要改以下nginx服务器的操作系统限制了。

优化的我都想吐血。

这几天一直在做这个优化。一定要把这个搞定之后，才能做其它的事情。

服务器内部错误，我就当做我项目的bug。
现在就是一定要解决504超时问题和系统方面的限制。

经过我的努力，最终将并发数提高到了1500.

还没有结束，下一次优化继续。今天 到此为止。

准备出去吃饭时看了一下，又504了。伤心了。

改为1000，盯着，5分钟之后再出去。

最终还是不能解决nginx -> 数据中心的504错误。

不过比之前的情况要好了很多，毕竟这是低配置。

1g内存，1核心cpu，1000个并发可以了。
跑了接近10分钟，1000个连接渐渐的趋于稳定了，504也没了。

最后再看下服务器的 cpu使用情况

数据中心，60% cpu使用率 运行tornaod的服务。

nginx毫无压力，2%

amqp 1%

mysql 72%

说明这个架构是错误的，
因为，amqp, nginx的利用率没有起来，cpu使用率最高的就是mysql和api服务。这里无法充分发挥
消息队列的性能，而且，还增加了mysql的负载。

不过，本人决定一错到底，决定优化。

```
pika.exceptions.ConnectionClosed: (320, 'Too Many Missed Heartbeats, No reply in 120 seconds')
```
由于1000个任务，所以导致出现了这个问题。太高也顶不住啊。

amqp随着任务的应答数增加，性能也明显降低，后来我又将并发数改为100，现在性能显著提高了。

哎，看来，机器的配置有时候存在很大的问题。

到最后，还是tmd torando处理不过来，吗的。

整个性能的瓶颈还是卡在了tornado，进而还是卡在了mysql上。

最后经过测试，假设客户端的超时时间在60秒以内，那么并发只能支持10个线程同时操作。

可怜了。

而且10个后面都会大量报错。

所以，做nimab啊。要么增加api接口的配置，要么tm这项目就重写。玩你吗比。

方案是错的。

我看，什么基于http存储数据的api接口纯属中看不中用。

api接口一点p用都没。只能做门户网站。
tornado的异步我都做了。但是，就是tmd处理不过来。

码的，我把api服务运行在我的mac上时，居然就可以处理过来。

这次算过了一把瘾，玩了nginx的负载均衡，linux的并发参数优化，mysql的集群优化，总之到此为止。

程序没有优化的余地，硬件就是优化的方向。

吗的，老子怀疑tornado是单线程的。

# 总结
* 以后做方案的时候，如果发现可能有瓶颈，直接舍弃，要做就做没有瓶颈的方案。一开始我就知道了这里一定有瓶颈，还做了将近1个月。

伤心吗？当然。

写了那么多的代码居然是废品。觉得我不会伤心吗？


晚上想了想，既然torando是因为超时引起的，那么让tornado超时的原因在哪里呢？
 
数据库很快啊。sql语句我已经优化过了，比从前提高了将近50倍。
 
那么，当torando的高峰来临时，这么多的连接，平均一个连接使用一个mysql连接，那么我这1000个线程过来后，mysql有那么多线程可以使用吗？
另外 ，tornado是异步的，而我的连接池的实现是基于线程的。
 
那么 ，问题是，优化还是得从mysql的连接这里进行优化，其实这里有一个非常大的优化点。
关键 在于，10个，5个线程同时访问接口，为什么还会超时呢？
 
## 终于找到了和我出现一样问题的人
https://www.v2ex.com/t/262338

由于找到了解决方案，于是我决定再将自己的写的同步的mysql连接池和异步的mysql连接池做一个对比，
最后发现，异步的查询速度是同步查询速度的15倍。
tornado真是个好东西。

## 昨天封装了一个mysql连接池工厂，结果今天用在tornado中，出现ioloop is already running 错误
写了这么多代码，最后性能卡在异步的mysql上。想换语言，但是，要将之前写的代码都作废，挫败感相当强。

究竟是人的不可靠还是mysql根本就不能异步，异步反正不可靠。我换成同步的连接池后就不会报错。
但是，昨天测试异步比同步要快的。

证明了mysql这里用异步是行不通的。由于tornado的事件循环又要对http请求处理，又要处理mysql，可能处理不过来，所以




，并且torndo官方也有建议就是说，如果是柱塞的代码，必须要使用连接池来做。

可怜的sql烂语句，今天将多个插入弄成一条sql语句，总体来说，又提高了将近25倍，之前优化的sql语句提高了50倍将近，现在50 * 25 性能
提高了将近1000倍。

client 134 % cpu

server 15 % cpu

客户端已经没有优化的空间了，但是服务端cpu利用率还没到100

一会拿到linux下做做测试。

通过nginx的反向代理到数据中心的两个实例，数据中心双核CPU,1G内存，爬虫客户端5,100线程都测试过，总体来说这次数据中心比较稳定了。数据中心cpu使用率（两个实例的，不知道为什么，nginx总是不能将负载均衡到这两个实例上，总是一个实例cpu在60%左右），可能和虚拟机有关，下次要测试下真实的物理机，可能会有更大的收获。

mysql异步等哪天需求增加了，再弄了，上次说到，同步比异步慢好像是20倍左右。我忘记了反正同步比异步mysql操作要慢。

<<<<<<< HEAD
# 压力测试
500个线程出现
```
nginx connection reset by peer
```
知识:

	Web网站的几个并发量级
	评价一个网站的“大小”，处于视角的不同，有很多种衡量的方法，类似文章数，页面数之类的数据非常明显，也没有什么可以争议的。但对于并发来说，争议非常之多，这里就从一个技术的角度开始，谈谈几个Web网站的数量级。

	相信很多人谈论一个网站的热度，总免不了会询问日均PV，同时在线人数、注册用户数等运营数据，说实话从技术角度来说，这几个数值没有一个可以放在一起比较的——一个静态网站的PV跟一个SNS类/Web Game网站的PV根本就不是一回事。由于互联网有一个传说中的“3秒定律”，可能当下更多的网站技术指标要求1.5秒以内加载整页，或者至少可以达到阅读的标准。如果要较真什么“同时在线”，毫不客气的说，对于HTTP这类短链接的网络协议来说，在WebSocket还不普及的时代，能统计在线纯属扯淡，唯一能做的只是取个时间段，计算下访问用户而已。这些依然可以换算成QPS（Quest Per Second每秒请求数）。就并发而言，我唯一推崇的只有理论最大QPS和悲观QPS。

	 

	这里就大致根据理论最大QPS，给网站做几个分类

	50QPS以下——小网站

	没什么好说的，简单的小网站而已，就如同本站这样，你可以用最简单的方法快速搭建，短期没有太多的技术瓶颈，只要服务器不要太烂就好。

	50～100QPS——DB极限型

	大部分的关系型数据库的每次请求大多都能控制在0.01秒左右，即便你的网站每页面只有一次DB请求，那么页面请求无法保证在1秒钟内完成100个请求，这个阶段要考虑做Cache或者多DB负载。无论那种方案，网站重构是不可避免的。

	300～800QPS——带宽极限型

	目前服务器大多用了IDC提供的“百兆带宽”，这意味着网站出口的实际带宽是8M Byte左右。假定每个页面只有10K Byte，在这个并发条件下，百兆带宽已经吃完。首要考虑是CDN加速／异地缓存，多机负载等技术。

	500～1000QPS——内网带宽极限＋Memcache极限型

	由于Key/value的特性，每个页面对memcache的请求远大于直接对DB的请求，Memcache的悲观并发数在2w左右，看似很高，但事实上大多数情况下，首先是有可能在次之前内网的带宽就已经吃光，接着是在8K QPS左右的情况下，Memcache已经表现出了不稳定，如果代码上没有足够的优化，可能直接将压力转嫁到了DB层上，这就最终导致整个系统在达到某个阀值之上，性能迅速下滑。

	1000～2000QPS——FORK/SELECT，锁模式极限型

	好吧，一句话：线程模型决定吞吐量。不管你系统中最常见的锁是什么锁，这个级别下，文件系统访问锁都成为了灾难。这就要求系统中不能存在中央节点，所有的数据都必须分布存储，数据需要分布处理。总之，关键词：分布

	2000QPS以上——C10K极限

	尽管现在很多应用已经实现了C25K，但短板理论告诉我们，决定网站整体并发的永远是最低效的那个环节。我承认我生涯中从未遇到过2000QPS以上，甚至1.5K以上的网站，希望有此经验的哥们可以一起交流下

* 吞吐量指的是每秒完成的请求数TPS
1G 1核， 最高60 tps/s

线程数500, 2000的时候，jmeter的错误率为27%，吞吐量为72，
200 到 500 err为1.8% 吞吐量为58

最后将线程改为100的时候，吞吐量为46，err为0%，所以，可以得出结论，
我这个优化了将近几个星期的api接口的并发数就为100个线程了。

我是在想，他们那些人2000个线程的并发是怎么做出来的。
=======
mysql驱动还有优化的余地，集群和异步。
