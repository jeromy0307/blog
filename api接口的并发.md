# api接口的并发
30万数据，尚且还可以处理过来，可是现在数据达到了41万，我启动了一个tornado进程方法都用的异步。
客户端连接超时时间120秒，都超时异常。之前没有这种情况，一开始数据量小的时候，tornado的响应
时间均在2秒左右，后来慢慢的上升之6秒左右。

现在还只有20个线程同时访问。

这叫什么并发，人家的并发都是单进程可以跑2000多个线程。我这才20个线程就顶不住了。

那我提高客户端的线程数来做，现在我将客户端的线程数提高到2000，tornado进程数不变，我来测试。

经过我测试，发现tornado处理的速度特别快，但是还是存在客户端不能创建请求的过程。那么问题出在哪里了呢？

弄上负载均衡nginx反向代理。

由于上一个实验造成tornado单进程，客户端存在大量超时连接。所以，这次准备利用反向代理来慢慢增加tornado的
进程数，然后来试试。

首先，我装了一台nginx的服务器ubuntu虚拟机。

然后再装两台部署tornado应用的ubuntu虚拟机。

为了慢慢的查看tornado的性能，所以我准备慢慢增加tornado进程数。

PS. 由于之前的一个app，说数百万并发，现在我把之前的app经历拿到这里，发现20多个都顶不住，那么，如何去谈
百万并发的app呢？这里我感觉很不靠谱了。

我测试了下单条mysql查询，发现查询速度很快只需要0.718秒，这说明不是我的myslq性能慢，从这里，至少可以
推断出，可能是写数据库操作导致等待，那么我的mysql表的引擎室inodb，网上有人说
inodb.

当然，我要去搜索这个问题的原因是，那是因为我做了一个测试，就是当我把程序全部关掉之后，执行单个查询语句的速度是0.718秒，那么问题来了，如果我把程序再开起来，这个速度会稳定吗？假设稳定，就可以断定，是因为inodb的高并发写入表的操作引起了速度的tornado并发性能的下降。

那么，再做一次实验，首先开启tornado服务端单进程，然后开启客户端2000个线程。现在再到mysql workbench上查询一次，看看速度是多少？

引申一些条件，由于一开始我的数据库已经有了30多万电影数据，这次虽然又增加了10万多的数据，但是写入也只是写入了10多万数据，这样存在高并发吗？平均每秒都不超过20个插入，怎么可能会存在高并发写入的问题呢？

所以，最后基本能够确定的问题有亮点：
* tornado mac单进程处理能力不行;
* 很小的因素在mysql这边；

算了直接贴上知乎上大神的评论。
https://www.zhihu.com/question/23445395

首先我筛选前几个答案，因为这些答案比较靠前，所以就用这几个作为参考。

## 关于insert高并发是用inodb还是myiasm
### 答案1
TokuDB--它的fractal tree（其实就是buffered tree）能把随机IO变为顺序IO，写入性能极强，我们测试在HDD是InnoDB的3倍以上~Myisam官方已经放弃维护了，虽然插入性能也行，但不是crash safe且crash后恢复时间长，而且只有索引能缓存在内存中，所以都不一定比有热数据缓存的的InnoDB快；不要用了~

作者：刀尖红叶
链接：https://www.zhihu.com/question/23445395/answer/62345043
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

### 答案2
选择innodb还是MyISAM

如果不是对事物要求非常的强，高并发写推荐myisam。理由如下：

  1. myisam的索引和数据是分开的，并且索引是有压缩的，内存使用率就相应提高了不少，能加载更多索引，而innodb是所以和数据是紧密捆绑的，没有使用压缩从而造成innodb比myisam的体积庞大不少；
  2. innodb 存储引擎在插入数据时会花更多的开销在维护完整性，维持事物上，所以效率比myisam低；
  3. 主要是插入数据，并且只有一张表，后期对该表的操作主要是查询，就是查询速度而言，myisam比innodb更优越，并且还有myisam索引，可以很好的优化查询速度。

如何提高insert效率

假设每秒5W~7W的量，并且数据是实时产生的，如何优化？

1. 批量插入values，而不是每一次都插入一条数据；
2. 删除mysql都索引，有索引存在插入速度会受很大的影响；
3. 增加主键；

### 答案3
作者：吴强 Daniel
链接：https://www.zhihu.com/question/23445395/answer/52080020
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

单线程MyISAM插入更快. innodb_flush_log_at_trx_commit=1, 禁止auto commit, 不要用单个线程或者进程插入, 同时模拟100个客户端插入, 你会发现InnoDB插入比MyISAM快. 当你更新的数据主键非常离散的时候, InnoDB可以用多个row lock而MyISAM总是lock整个table一条一条插入, MyISAM会比InnoDB慢. 事实上, MyISAM严格意义上根本不算是个数据库引擎, 最多算个结构化文件存储引擎. 在我的MBP上32个线程总共插入32万条记录, MyISAM大概是17.5秒, InnoDB大概16秒不到, 32个线程随机更新更新是MyISAM 23秒对InnoDB 19秒. 我的MBP是多通道的SSD, 如果在硬盘上测试差距会更大. 所以, 好多同学在单线程下auto-commit的测试来证明MyISAM比InnoDB快是不靠谱的. 但是无论如何, 大量插入还是NoSQL方便, 你7万的tps已经很高了, 已经非常不适合MySQL了, 如果只是峰值这样高, 建议你用文件或者队列buffer一下慢慢插, 如果是持续性的这样的TPS, 建议用append类型的NoSQL, 比如cassandra 和 redis. Netflix曾经在AWS上做过实验,288个m1el节点可以达到每秒一百万次写入, 基于SSD的商业数据库Aerospike更是只要50个节点 (参考 Daniel's Blog: Cassandra and Aerospike, the one million TPS war).

不过由于上面的测试还没开始，要等mac上复制文件完毕才能。

# 总结
通过这次并发方面的探索，我总结出下面一些要点：
* 并发要看cpu的核心数，linux系统的优化成都；
* 并发要看tornado应用的设置；
* 并发要看mysql方面的设置；

就本次优化过程而言，最终决定采用慢慢增加tornado进程数的方法也就是负载均衡的方法来解决本次的问题，如果再出现客户端还是大量超时的情况，我觉得就只能再增加tornado的进程数，后端的程序代码，我都是手写的，读写分离数据库，很简单。就算到时候，是因为查询速度太慢，我这里也没有办法解决，因为查询我都是用的精确字符串，没有用到模糊匹配的方式来查询。因为当你查询一件商品是否存在数据库的时候，一定是用字符串去匹配。

所以，最终的并发优化的方式，就是，增加应用的配置（机器的配置增加就是单机增加物理机器的配置，负载均衡，就是横向扩展增加机器集群来抗压力）。

这里假设瓶颈是卡在了mysql上，那么，似乎是无法优化的，mysql的速度慢了，那么，就算你tornado无限多，mysql一直柱塞，也根本就没什么办法。

后期我会增加我做了负载均衡上面测试之后的测试结果。

不知为何mac上的文件复制有问题，我将移动硬盘上的30多g的文件夹复制到mac上，mac就是不能用fiddler打开。

本来昨天就准备做负载均衡测试和tornado并发调优的实验的。

因为只有搞定了这个，我的项目的后续工作才能展开。

可是当我把客户端和服务端都启动起来之后发现，mysql的查询也非常的快，那么可以断定了，就是tornado搞不过来。看来我得多启动几个了。

由于我用的是mac，所以不知道能否发挥tornado的异步优势，所以，下次得到linux下测试才能得到结果。可能不是tornado的锅。

python的异步有点不可靠，可能是人的不可靠。

这次我说了，以后，如果要设计api接口的话，我尽量不用异步；
然后，如果要设计涉及支付的api接口，我尽量用java来写。

这python或者说我的能力不足以驾驭这门语言。so？就这样放弃了？

我的意思是说，做爬虫，我用python，但是做api接口我要用java。所以，似乎我也要开始准备我的java开发之路了，就是
用java来重构pyhton写的api接口。

问题是，我的mysql连接池有问题。由于是轮训，并且，算了不想说了，这里的问题很难处理。由于默认的连接池已经使用
，所以导致没有mysql连接可以使用，所以，导致，tornado超时，tornado超时就是超时在获取可用的mysql连接这里。

我都想换语言了。虽然这些东西都是自己设计都，运行环境也是极低的。但是这不能说明问题。

一开始我觉得是mysql连接池不够用，从而导致一直轮训获取连接，结果，这次我客户端启动5个线程，tornado都处理不过来。当然是单进程的 tornado，我的目标是让tornado处理2000个连接。可是现在，连5个并发访问都可能会出现问题。
当然这是在mac下做的测试。总体来说，心情不是很好。

场景是，5个线程同时抓数据，然后将数据发送到api接口，当然这个请求的数据很大，每次大概要插入24个，so这些数据在插入数据库之前必须验证数据库中不存在，mysql里有一个insert ignore into，这个可以一试。要是还是慢，那么，再想
办法。
